{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/opt/python/bin/python3.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import uniform, expon, poisson, describe\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is to fix heuristic 1 and develop heuristic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'slurm scripts/data/08-14-20/path_points/'\n",
    "\n",
    "points = []\n",
    "distances = []\n",
    "lengths_based = []\n",
    "counts = []\n",
    "\n",
    "T_n_indices = defaultdict(list)\n",
    "\n",
    "for i in range(1,501):\n",
    "    # something weird happened, if i is 0 mod 50 the file doesn't exist...\n",
    "    #if i % 50 == 0:\n",
    "    #    continue\n",
    "    \n",
    "    f = open(filename+str(i)+'-dim2-n5000000_pathpoints.pkl', \"rb\")\n",
    "    pathpoints = pickle.load(f)\n",
    "    points.append(pathpoints)\n",
    "    s_n = 0\n",
    "    for j in range(len(pathpoints)-2):\n",
    "        s_n += np.linalg.norm(pathpoints[j+1] - pathpoints[j])\n",
    "    lengths_based.append(s_n)\n",
    "    distances.append(s_n + np.linalg.norm(pathpoints[-1] - pathpoints[-2]))\n",
    "    counts.append(len(pathpoints)-2)\n",
    "    T_n_indices[len(pathpoints)-2].append(i)\n",
    "    \n",
    "    if pathpoints[-1][0] != 0.9 or pathpoints[-1][1] != 0.9:\n",
    "        print(i)\n",
    "\n",
    "        \n",
    "distances = np.array(distances)\n",
    "lengths_based = np.array(lengths_based)\n",
    "counts_based = np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000000\n",
    "D = 2\n",
    "\n",
    "ell = 0.8 * np.sqrt(2)\n",
    "\n",
    "x_init = np.array([0, 0])\n",
    "x_goal = np.array([ell, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_n function\n",
    "def r(n, D):\n",
    "    return (n ** (-1/(2*D))) / 5\n",
    "    # designed for n = 5 * 10^6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates random sample of n points (not including init and goal) -- poisson functionality added\n",
    "def SampleFree(n, d, x_init, x_goal, distr='unif'):\n",
    "    assert distr in {'unif', 'pois'}, \"distr parameter must be one of the following: 'unif', 'pois'\"\n",
    "    \n",
    "    # start with init point (index 0)\n",
    "    V = [x_init]\n",
    "    \n",
    "    if distr is 'pois':\n",
    "        num_points = np.random.poisson(lam=n)\n",
    "    else:\n",
    "        num_points = n\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        point = np.random.uniform(size=d)\n",
    "        if (point[0]-0.5)**2 - 1.997 * (point[0]-0.5) * (point[1]-0.5) + (point[1]-0.5)**2 > 1/1800:\n",
    "            continue\n",
    "        V.append(point)\n",
    "        \n",
    "    # add the goal point (index n + 1)\n",
    "    V.append(x_goal)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creates adjacency list, no need for also storing their distances\n",
    "def Near(V, r_n):\n",
    "    \n",
    "    # Create a KD Tree first\n",
    "    KDT = KDTree(data=V)\n",
    "    \n",
    "    # Create the KD Tree to search against\n",
    "    search_against = KDTree(data=V)\n",
    "\n",
    "    # run query_ball_tree; returns list of lists\n",
    "    results = KDT.query_ball_tree(other=search_against, r=r_n)\n",
    "    \n",
    "    # for vertex indexed by i, results[i] contains all indices j such that dist(v[i],v[j]) < r\n",
    "    edges = [None] * len(V)\n",
    "    for i in range(len(V)):\n",
    "        edges[i] = []\n",
    "        for j in results[i]:\n",
    "            if i != j:\n",
    "                edges[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Afore-mentioned graph heuristic\n",
    "def path_algorithm(V, E):\n",
    "    # V is the vertex set, E is the output of the KDT function (both numpy arrays)\n",
    "    x_init = V[0]\n",
    "    x_goal = V[-1]\n",
    "    \n",
    "    # tracks where we've been (array of indices)\n",
    "    piece = 0\n",
    "    visited = [0]\n",
    "    distance = 0\n",
    "    \n",
    "    # boolean indicator of something going wrong, e.g. no further point or repeat node\n",
    "    failure = False\n",
    "    #print((failure is False) and (piece != len(V)-1))\n",
    "    \n",
    "    while (failure is False) and (piece != len(V)-1):\n",
    "        candidates = np.take(V, np.array(E[piece]), axis=0)\n",
    "        angles = []\n",
    "        for p in candidates:\n",
    "            vect_1 = p - V[piece]\n",
    "            vect_2 = x_goal - V[piece]\n",
    "            angle = math.atan2( vect_1[0]*vect_2[1] - vect_1[1]*vect_2[0], vect_1[0]*vect_2[0] + vect_1[1]*vect_2[1])\n",
    "            angles.append(np.abs(angle))             # absolute angle in radians\n",
    "        next_piece = E[piece][np.array(angles).argmin()]\n",
    "        if next_piece in visited:\n",
    "            #print('failed')\n",
    "            #print(next_piece)\n",
    "            #print(visited)\n",
    "            failure = True            # means we have already been to this node\n",
    "        else:\n",
    "            distance += np.linalg.norm(V[next_piece] - V[piece])\n",
    "            visited.append(next_piece)\n",
    "            piece = next_piece\n",
    "            \n",
    "    path_nodes = []\n",
    "    for v in visited:\n",
    "        path_nodes.append(V[v])\n",
    "    \n",
    "    if failure:\n",
    "        return path_nodes, float('inf')\n",
    "    \n",
    "    else:\n",
    "        return path_nodes, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_rej(seed, process=1):\n",
    "    np.random.seed(seed) \n",
    "    \n",
    "    results = defaultdict(lambda: float('inf'))\n",
    "    results['seed'] = seed\n",
    "    \n",
    "    X = [x_init[0]]\n",
    "    Y = [x_init[1]]\n",
    "    \n",
    "    lmbda = (n * (r(n, D) ** 2) * math.pi)\n",
    "    \n",
    "    # WARNING: note the 0-index entries! these are not actual data and will mess with the statistics\n",
    "    R = [r(n, D)]\n",
    "    Theta = [0]\n",
    "    S = [0]\n",
    "    Gamma = [0]\n",
    "\n",
    "    t = 0\n",
    "    while np.linalg.norm(np.array([X[-1], Y[-1]]) - x_goal) > r(n, D) and t < 2000:\n",
    "        t += 1 # timestep index\n",
    "\n",
    "        # three samples for each time step\n",
    "        # rejection sampling (to account for dependence between balls of adjacent timesteps)\n",
    "        reject = True\n",
    "        while reject:\n",
    "            r_sample = r(n, D) * (np.random.uniform() ** 0.5)\n",
    "            s_sample = np.random.choice(a=[-1, 1])\n",
    "            if process == 1:\n",
    "                th_sample = (math.pi / lmbda) * np.random.exponential()       # uses asymptotics on the # of points in a ball explicitly\n",
    "            elif process == 2:\n",
    "                n_B = np.random.poisson((r(n, D) ** 2) * math.pi * n)         # simulates the number of points in a ball, leading to a mixture of exponentials\n",
    "                th_sample = (math.pi / n_B) * np.random.exponential()\n",
    "            \n",
    "            # reject if (r_next < r(n)-r_now AND theta_next < theta_now)\n",
    "            if not (r_sample < r(n, D) - R[-1] and th_sample < Theta[-1]):\n",
    "                reject = False\n",
    "            \n",
    "        R.append(r_sample)\n",
    "        S.append(s_sample)\n",
    "        if process == 1:\n",
    "            Theta.append(th_sample)   \n",
    "        elif process == 2:   \n",
    "            Theta.append(th_sample)\n",
    "                                   \n",
    "        # now we can determine the rest\n",
    "        X.append(X[t-1] + R[t] * np.cos(Gamma[t-1] - Theta[t] * S[t]))\n",
    "        Y.append(Y[t-1] + R[t] * np.sin(Gamma[t-1] - Theta[t] * S[t]))\n",
    "\n",
    "        g = np.arcsin((R[t] / np.linalg.norm(np.array([X[t], Y[t]]) - x_goal)) * np.sin(Theta[t] * S[t]))\n",
    "        Gamma.append(Gamma[t-1] + g)\n",
    "        \n",
    "    if t < 1000:\n",
    "        results['T'] = t\n",
    "        results['length'] = sum(R[1:])\n",
    "        results['last_point'] = (X[-1], Y[-1])\n",
    "        results['distance_to_goal'] = np.linalg.norm(np.array([X[-1], Y[-1]]) - x_goal) \n",
    "        results['R'] = R\n",
    "        results['Theta'] = Theta\n",
    "        results['S'] = S\n",
    "        results['X'] = X\n",
    "        results['Y'] = Y\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_outputs_1 = defaultdict(dict)\n",
    "simulation_outputs_2 = defaultdict(dict)\n",
    "\n",
    "for i in range(1, 1001):\n",
    "    simulation_outputs_1[i] = run_simulation_rej(i * 100, 1)\n",
    "    simulation_outputs_2[i] = run_simulation_rej(i * 200, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_free = {1 : [], 2 : []}\n",
    "for k in simulation_outputs_1.keys():\n",
    "    lengths_free[1].append(simulation_outputs_1[k]['length'])\n",
    "    lengths_free[2].append(simulation_outputs_2[k]['length'])\n",
    "    \n",
    "lengths_free[1] = np.array(lengths_free[1])\n",
    "lengths_free[2] = np.array(lengths_free[2])\n",
    "\n",
    "counts_free = {1 : [], 2 : []}\n",
    "for k in simulation_outputs_1.keys():\n",
    "    counts_free[1].append(simulation_outputs_1[k]['T'])\n",
    "    counts_free[2].append(simulation_outputs_2[k]['T'])\n",
    "    \n",
    "counts_free[1] = np.array(counts_free[1])\n",
    "counts_free[2] = np.array(counts_free[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=500, minmax=(0.00017891251733326285, 0.00422558055945399), mean=0.001826468253166701, variance=1.0785253729415668e-06, skewness=0.2915675690835668, kurtosis=-0.7972677266609938)\n",
      "DescribeResult(nobs=1000, minmax=(0.00015239665612232223, 0.00432112358874881), mean=0.0017220764890354128, variance=1.0789817741103442e-06, skewness=0.4119366401436809, kurtosis=-0.8156486069069042)\n",
      "DescribeResult(nobs=1000, minmax=(0.00013226630043128296, 0.004252147560128483), mean=0.0017376367930726077, variance=1.0385456389154292e-06, skewness=0.3757084198615512, kurtosis=-0.7640511156893557)\n"
     ]
    }
   ],
   "source": [
    "# statistics on length\n",
    "const = ell - r(n, D)\n",
    "\n",
    "print(describe(lengths_based - const))\n",
    "print(describe(lengths_free[1] - const))\n",
    "print(describe(lengths_free[2] - const))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=500, minmax=(367, 397), mean=380.966, variance=26.485815631262525, skewness=0.13994369244472263, kurtosis=0.02224633502166906)\n",
      "DescribeResult(nobs=1000, minmax=(368, 403), mean=384.177, variance=32.099770770770775, skewness=0.05793985668671628, kurtosis=0.02372214346417323)\n",
      "DescribeResult(nobs=1000, minmax=(368, 403), mean=384.138, variance=29.092048048048053, skewness=0.24501947709587263, kurtosis=0.06816466747428596)\n"
     ]
    }
   ],
   "source": [
    "# statistics on T\n",
    "\n",
    "print(describe(counts_based)) # graph based\n",
    "print(describe(counts_free[1]))  # graph free process 1\n",
    "print(describe(counts_free[2]))  # graph free process 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=500, minmax=(21.60927272174488, 22.528879188945318), mean=22.03509885359079, variance=0.02300926832944089, skewness=0.1357297046350247, kurtosis=0.06549345589638111)\n",
      "DescribeResult(nobs=1000, minmax=(21.643974041947722, 22.669086061470452), mean=22.125619616516676, variance=0.02735575210970632, skewness=0.037950637750920606, kurtosis=0.008051285554572463)\n",
      "DescribeResult(nobs=1000, minmax=(21.65623214232296, 22.705496413777496), mean=22.124864955671402, variance=0.025111127806937295, skewness=0.23657585351558258, kurtosis=0.06467974529432974)\n"
     ]
    }
   ],
   "source": [
    "# statistics on L(sqrt T)\n",
    "\n",
    "print(describe((counts_based ** 0.5) * lengths_based )) # graph based\n",
    "print(describe((counts_free[1] ** 0.5) * lengths_free[1] ))  # graph free process 1\n",
    "print(describe((counts_free[2] ** 0.5) * lengths_free[2] ))  # graph free process 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_outputs_1 = defaultdict(dict)\n",
    "simulation_outputs_2 = defaultdict(dict)\n",
    "\n",
    "for i in range(1, 1001):\n",
    "    simulation_outputs_1[i] = run_simulation_rej(i * 100, 1)\n",
    "    simulation_outputs_2[i] = run_simulation_rej(i * 200, 2)\n",
    "    \n",
    "lengths_free = {1 : [], 2 : []}\n",
    "for k in simulation_outputs_1.keys():\n",
    "    lengths_free[1].append(simulation_outputs_1[k]['length'])\n",
    "    lengths_free[2].append(simulation_outputs_2[k]['length'])\n",
    "    \n",
    "lengths_free[1] = np.array(lengths_free[1])\n",
    "lengths_free[2] = np.array(lengths_free[2])\n",
    "\n",
    "counts_free = {1 : [], 2 : []}\n",
    "for k in simulation_outputs_1.keys():\n",
    "    counts_free[1].append(simulation_outputs_1[k]['T'])\n",
    "    counts_free[2].append(simulation_outputs_2[k]['T'])\n",
    "    \n",
    "counts_free[1] = np.array(counts_free[1])\n",
    "counts_free[2] = np.array(counts_free[2])\n",
    "\n",
    "\n",
    "# statistics on length\n",
    "const = ell - r(n, D)\n",
    "print('L_n')\n",
    "print(describe(lengths_based - const))\n",
    "print(describe(lengths_free[1] - const))\n",
    "print(describe(lengths_free[2] - const))\n",
    "\n",
    "# statistics on T\n",
    "\n",
    "print('T_n')\n",
    "print(describe(counts_based)) # graph based\n",
    "print(describe(counts_free[1]))  # graph free process 1\n",
    "print(describe(counts_free[2]))  # graph free process 2\n",
    "\n",
    "# statistics on L(sqrt T)\n",
    "\n",
    "print('asymp')\n",
    "print(describe((counts_based ** 0.5) * lengths_based )) # graph based\n",
    "print(describe((counts_free[1] ** 0.5) * lengths_free[1] ))  # graph free process 1\n",
    "print(describe((counts_free[2] ** 0.5) * lengths_free[2] ))  # graph free process 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
