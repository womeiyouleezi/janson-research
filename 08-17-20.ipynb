{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/opt/python/bin/python3.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import uniform, expon, poisson, describe\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is to fix heuristic 1 and develop heuristic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "filename = 'slurm scripts/data/08-14-20/path_points/'\n",
    "\n",
    "points = []\n",
    "distances = []\n",
    "lengths_based = []\n",
    "counts = []\n",
    "\n",
    "T_n_indices = defaultdict(list)\n",
    "\n",
    "for i in range(1,501):\n",
    "    # something weird happened, if i is 0 mod 50 the file doesn't exist...\n",
    "    #if i % 50 == 0:\n",
    "    #    continue\n",
    "    \n",
    "    f = open(filename+str(i)+'-dim2-n5000000_pathpoints.pkl', \"rb\")\n",
    "    pathpoints = pickle.load(f)\n",
    "    points.append(pathpoints)\n",
    "    s_n = 0\n",
    "    for j in range(len(pathpoints)-2):\n",
    "        s_n += np.linalg.norm(pathpoints[j+1] - pathpoints[j])\n",
    "    lengths_based.append(s_n)\n",
    "    distances.append(s_n + np.linalg.norm(pathpoints[-1] - pathpoints[-2]))\n",
    "    counts.append(len(pathpoints)-2)\n",
    "    T_n_indices[len(pathpoints)-2].append(i)\n",
    "    \n",
    "    if pathpoints[-1][0] != 0.9 or pathpoints[-1][1] != 0.9:\n",
    "        print(i)\n",
    "\n",
    "        \n",
    "distances = np.array(distances)\n",
    "lengths_based = np.array(lengths_based)\n",
    "counts_based = np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000000\n",
    "D = 2\n",
    "\n",
    "ell = 0.8 * np.sqrt(2)\n",
    "\n",
    "x_init = np.array([0, 0])\n",
    "x_goal = np.array([ell, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_n function\n",
    "def r(n, D):\n",
    "    return (n ** (-1/(2*D))) / 5\n",
    "    # designed for n = 5 * 10^6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_max = math.pi * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_r = n * (math.pi * (r(n, D) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280.9925892416291\n",
      "0.3141592653589793\n",
      "88.27642540746763\n"
     ]
    }
   ],
   "source": [
    "print(lambda_r)\n",
    "print(th_max)\n",
    "print(lambda_r * th_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates random sample of n points (not including init and goal) -- poisson functionality added\n",
    "def SampleFree(n, d, x_init, x_goal, distr='unif'):\n",
    "    assert distr in {'unif', 'pois'}, \"distr parameter must be one of the following: 'unif', 'pois'\"\n",
    "    \n",
    "    # start with init point (index 0)\n",
    "    V = [x_init]\n",
    "    \n",
    "    if distr is 'pois':\n",
    "        num_points = np.random.poisson(lam=n)\n",
    "    else:\n",
    "        num_points = n\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        point = np.random.uniform(size=d)\n",
    "        if (point[0]-0.5)**2 - 1.997 * (point[0]-0.5) * (point[1]-0.5) + (point[1]-0.5)**2 > 1/1800:\n",
    "            continue\n",
    "        V.append(point)\n",
    "        \n",
    "    # add the goal point (index n + 1)\n",
    "    V.append(x_goal)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates adjacency list, no need for also storing their distances\n",
    "def Near(V, r_n):\n",
    "    \n",
    "    # Create a KD Tree first\n",
    "    KDT = KDTree(data=V)\n",
    "    \n",
    "    # Create the KD Tree to search against\n",
    "    search_against = KDTree(data=V)\n",
    "\n",
    "    # run query_ball_tree; returns list of lists\n",
    "    results = KDT.query_ball_tree(other=search_against, r=r_n)\n",
    "    \n",
    "    # for vertex indexed by i, results[i] contains all indices j such that dist(v[i],v[j]) < r\n",
    "    edges = [None] * len(V)\n",
    "    for i in range(len(V)):\n",
    "        edges[i] = []\n",
    "        for j in results[i]:\n",
    "            if i != j:\n",
    "                edges[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph heuristic where in a sector of width theta_max about the beeline we take the point with max R\n",
    "def path_algorithm_2(V, E):\n",
    "    # V is the vertex set, E is the output of the KDT function (both numpy arrays)\n",
    "    x_init = V[0]\n",
    "    x_goal = V[-1]\n",
    "    \n",
    "    # tracks where we've been (array of indices)\n",
    "    piece = 0\n",
    "    visited = [0]\n",
    "    distance = 0\n",
    "    \n",
    "    # boolean indicator of something going wrong, e.g. no further point or repeat node\n",
    "    failure = False\n",
    "    #print((failure is False) and (piece != len(V)-1))\n",
    "    \n",
    "    while (failure is False) and (piece != len(V)-1):\n",
    "        candidates = np.take(V, np.array(E[piece]), axis=0)\n",
    "        angles = []\n",
    "        for p in candidates:\n",
    "            vect_1 = p - V[piece]\n",
    "            vect_2 = x_goal - V[piece]\n",
    "            angle = math.atan2( vect_1[0]*vect_2[1] - vect_1[1]*vect_2[0], vect_1[0]*vect_2[0] + vect_1[1]*vect_2[1])\n",
    "            angles.append(np.abs(angle))             # absolute angle in radians\n",
    "        next_piece = E[piece][np.array(angles).argmin()]\n",
    "        if next_piece in visited:\n",
    "            #print('failed')\n",
    "            #print(next_piece)\n",
    "            #print(visited)\n",
    "            failure = True            # means we have already been to this node\n",
    "        else:\n",
    "            distance += np.linalg.norm(V[next_piece] - V[piece])\n",
    "            visited.append(next_piece)\n",
    "            piece = next_piece\n",
    "            \n",
    "    path_nodes = []\n",
    "    for v in visited:\n",
    "        path_nodes.append(V[v])\n",
    "    \n",
    "    if failure:\n",
    "        return path_nodes, float('inf')\n",
    "    \n",
    "    else:\n",
    "        return path_nodes, distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
