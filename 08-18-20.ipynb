{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/opt/python/bin/python3.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import uniform, expon, poisson, describe\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(seed, process=1):\n",
    "    np.random.seed(seed) \n",
    "    \n",
    "    results = defaultdict(lambda: float('inf'))\n",
    "    results['seed'] = seed\n",
    "    \n",
    "    X = [x_init[0]]\n",
    "    Y = [x_init[1]]\n",
    "    \n",
    "    lmbda = (n * (r(n, D) ** 2) * math.pi)\n",
    "\n",
    "    R = [None]\n",
    "    Theta = [None]\n",
    "    S = [None]\n",
    "    Gamma = [0]\n",
    "\n",
    "    t = 0\n",
    "    while np.linalg.norm(np.array([X[-1], Y[-1]]) - x_goal) > r(n, D) and t < 2000:\n",
    "        t += 1 # timestep index\n",
    "\n",
    "        # three samples for each time step\n",
    "        R.append(r(n, D) * (np.random.uniform() ** 0.5))\n",
    "        S.append(np.random.choice(a=[-1, 1]))\n",
    "        if process == 1:\n",
    "            Theta.append((math.pi / lmbda) * np.random.exponential())   # uses asymptotics on the # of points in a ball explicitly\n",
    "        elif process == 2:\n",
    "            n_B = np.random.poisson((r(n, D) ** 2) * math.pi * n)       # simulates the number of points in a ball, leading to a mixture of exponentials\n",
    "            Theta.append((math.pi / n_B) * np.random.exponential())\n",
    "                                   \n",
    "        # now we can determine the rest\n",
    "        X.append(X[t-1] + R[t] * np.cos(Gamma[t-1] - Theta[t] * S[t]))\n",
    "        Y.append(Y[t-1] + R[t] * np.sin(Gamma[t-1] - Theta[t] * S[t]))\n",
    "\n",
    "        g = np.arcsin((R[t] / np.linalg.norm(np.array([X[t], Y[t]]) - x_goal)) * np.sin(Theta[t] * S[t]))\n",
    "        Gamma.append(Gamma[t-1] + g)\n",
    "        \n",
    "    if t < 1000:\n",
    "        results['T'] = t\n",
    "        results['length'] = sum(R[1:])\n",
    "        results['last_point'] = (X[-1], Y[-1])\n",
    "        results['distance_to_goal'] = np.linalg.norm(np.array([X[-1], Y[-1]]) - x_goal) \n",
    "        results['R'] = R\n",
    "        results['Theta'] = Theta\n",
    "        results['S'] = S\n",
    "        results['X'] = X\n",
    "        results['Y'] = Y\n",
    "        \n",
    "    return results\n",
    "\n",
    "def run_simulation_rej(seed, process=1):\n",
    "    np.random.seed(seed) \n",
    "    \n",
    "    results = defaultdict(lambda: float('inf'))\n",
    "    results['seed'] = seed\n",
    "    \n",
    "    X = [x_init[0]]\n",
    "    Y = [x_init[1]]\n",
    "    \n",
    "    lmbda = (n * (r(n, D) ** 2) * math.pi)\n",
    "    \n",
    "    # WARNING: note the 0-index entries! these are not actual data and will mess with the statistics\n",
    "    R = [r(n, D)]\n",
    "    Theta = [0]\n",
    "    S = [0]\n",
    "    Gamma = [0]\n",
    "\n",
    "    t = 0\n",
    "    while np.linalg.norm(np.array([X[-1], Y[-1]]) - x_goal) > r(n, D) and t < 2000:\n",
    "        t += 1 # timestep index\n",
    "\n",
    "        # three samples for each time step\n",
    "        # rejection sampling (to account for dependence between balls of adjacent timesteps)\n",
    "        reject = True\n",
    "        while reject:\n",
    "            r_sample = r(n, D) * (np.random.uniform() ** 0.5)\n",
    "            s_sample = np.random.choice(a=[-1, 1])\n",
    "            if process == 1:\n",
    "                th_sample = (math.pi / lmbda) * np.random.exponential()       # uses asymptotics on the # of points in a ball explicitly\n",
    "            elif process == 2:\n",
    "                n_B = np.random.poisson((r(n, D) ** 2) * math.pi * n)         # simulates the number of points in a ball, leading to a mixture of exponentials\n",
    "                th_sample = (math.pi / n_B) * np.random.exponential()\n",
    "            \n",
    "            # reject if (r_next < r(n)-r_now AND theta_next < theta_now)\n",
    "            if not (r_sample < r(n, D) - R[-1] and th_sample < Theta[-1]):\n",
    "                reject = False\n",
    "            \n",
    "        R.append(r_sample)\n",
    "        S.append(s_sample)\n",
    "        if process == 1:\n",
    "            Theta.append(th_sample)   \n",
    "        elif process == 2:   \n",
    "            Theta.append(th_sample)\n",
    "                                   \n",
    "        # now we can determine the rest\n",
    "        X.append(X[t-1] + R[t] * np.cos(Gamma[t-1] - Theta[t] * S[t]))\n",
    "        Y.append(Y[t-1] + R[t] * np.sin(Gamma[t-1] - Theta[t] * S[t]))\n",
    "\n",
    "        g = np.arcsin((R[t] / np.linalg.norm(np.array([X[t], Y[t]]) - x_goal)) * np.sin(Theta[t] * S[t]))\n",
    "        Gamma.append(Gamma[t-1] + g)\n",
    "        \n",
    "    if t < 1000:\n",
    "        results['T'] = t\n",
    "        results['length'] = sum(R[1:])\n",
    "        results['last_point'] = (X[-1], Y[-1])\n",
    "        results['distance_to_goal'] = np.linalg.norm(np.array([X[-1], Y[-1]]) - x_goal) \n",
    "        results['R'] = R\n",
    "        results['Theta'] = Theta\n",
    "        results['S'] = S\n",
    "        results['X'] = X\n",
    "        results['Y'] = Y\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "DescribeResult(nobs=1000, minmax=(0.0001345144988875724, 0.00428463147208058), mean=0.00173465986636877, variance=1.038372196513653e-06, skewness=0.36409614780069244, kurtosis=-0.8271217192521689)\n",
      " \n",
      "1-rej\n",
      "DescribeResult(nobs=1000, minmax=(0.00013020313858347343, 0.004282828158892471), mean=0.0017762423158081487, variance=9.99660767284966e-07, skewness=0.28922721884661234, kurtosis=-0.840580057086715)\n",
      " \n",
      "2\n",
      "DescribeResult(nobs=1000, minmax=(0.00012302208773662393, 0.004234521236498923), mean=0.0017721768229152807, variance=1.0962342577870154e-06, skewness=0.3305586120207213, kurtosis=-0.9050204382539513)\n",
      " \n",
      "2-rej\n",
      "DescribeResult(nobs=1000, minmax=(0.00014756185048314663, 0.004339574776342392), mean=0.0017604000465535525, variance=1.0518520497141016e-06, skewness=0.39819881251501155, kurtosis=-0.7802438590245697)\n",
      " \n",
      "1\n",
      "DescribeResult(nobs=1000, minmax=(373, 423), mean=400.207, variance=52.668819819819824, skewness=-0.09933534510938041, kurtosis=-0.04723805011446913)\n",
      " \n",
      "1-rej\n",
      "DescribeResult(nobs=1000, minmax=(367, 400), mean=383.909, variance=30.803522522522528, skewness=-0.023545124078987945, kurtosis=-0.1463543703802488)\n",
      " \n",
      "2\n",
      "DescribeResult(nobs=1000, minmax=(379, 424), mean=400.135, variance=48.7154904904905, skewness=0.10852938431761305, kurtosis=0.011216122628777025)\n",
      " \n",
      "2-rej\n",
      "DescribeResult(nobs=1000, minmax=(368, 401), mean=384.006, variance=27.897861861861866, skewness=0.09401368100654968, kurtosis=0.1650387087381655)\n",
      " \n",
      "1\n",
      "DescribeResult(nobs=1000, minmax=(21.781126029640703, 23.235466450076796), mean=22.582439646852222, variance=0.04268235378183909, skewness=-0.13023819848435436, kurtosis=0.04685150628510737)\n",
      " \n",
      "1-rej\n",
      "DescribeResult(nobs=1000, minmax=(21.611980409547954, 22.59924362672362), mean=22.118988504098454, variance=0.026433074443357484, skewness=0.007080609473110862, kurtosis=-0.20900553657689036)\n",
      " \n",
      "2\n",
      "DescribeResult(nobs=1000, minmax=(22.010381047602138, 23.23274979251251), mean=22.5812315908311, variance=0.03958474269609805, skewness=0.08377960425411599, kurtosis=-0.04185570186354681)\n",
      " \n",
      "2-rej\n",
      "DescribeResult(nobs=1000, minmax=(21.628779927953797, 22.6175126515214), mean=22.121521193291855, variance=0.0237319404404089, skewness=0.045322706551412684, kurtosis=0.11534470564977317)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "n = 5000000\n",
    "D = 2\n",
    "\n",
    "ell = 0.8 * np.sqrt(2)\n",
    "\n",
    "x_init = np.array([0, 0])\n",
    "x_goal = np.array([ell, 0])\n",
    "\n",
    "# r_n function\n",
    "def r(n, D):\n",
    "    return (n ** (-1/(2*D))) / 5\n",
    "    # designed for n = 5 * 10^6\n",
    "\n",
    "#############\n",
    "\n",
    "simulation_outputs = dict()     # key, value = process, dict\n",
    "\n",
    "for i in range(1, 3):\n",
    "    simulation_outputs[str(i)] = defaultdict(list)\n",
    "    simulation_outputs[str(i) + '-rej'] = defaultdict(list)\n",
    "    for j in range(1, 1001):\n",
    "        simulation_outputs[str(i)][j] = run_simulation(j * 10, process=i)\n",
    "        simulation_outputs[str(i) + '-rej'][j] = run_simulation_rej(j * 10, process=i)\n",
    "\n",
    "#############        \n",
    "\n",
    "lengths_free = defaultdict(list)\n",
    "counts_free = defaultdict(list)\n",
    "asymp_free = defaultdict(list)\n",
    "\n",
    "for k1 in simulation_outputs.keys():\n",
    "    for k2 in simulation_outputs[k1].keys():\n",
    "        lengths_free[k1].append(simulation_outputs[k1][k2]['length'])\n",
    "        counts_free[k1].append(simulation_outputs[k1][k2]['T'])\n",
    "        asymp_free[k1].append(simulation_outputs[k1][k2]['length'] * (simulation_outputs[k1][k2]['T'] ** 0.5))\n",
    "        \n",
    "const = ell - r(n, D)\n",
    "\n",
    "# statistics on length\n",
    "\n",
    "#print(describe(lengths_based - const))\n",
    "for k1 in simulation_outputs.keys():\n",
    "    print(str(k1))    \n",
    "    print(describe(lengths_free[k1] - const))\n",
    "    print(' ')\n",
    "    \n",
    "# statistics on T\n",
    "\n",
    "#print(describe(counts_based))\n",
    "for k1 in simulation_outputs.keys():\n",
    "    print(str(k1))    \n",
    "    print(describe(counts_free[k1]))\n",
    "    print(' ')\n",
    "    \n",
    "# statistics on asymp\n",
    "\n",
    "#print(describe(asymp_based))\n",
    "for k1 in simulation_outputs.keys():\n",
    "    print(str(k1))    \n",
    "    print(describe(asymp_free[k1]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "DescribeResult(nobs=1000, minmax=(0.008687432973464304, 0.01810107889298429), mean=0.01262592877630674, variance=2.0831954417861454e-06, skewness=0.3089137593170177, kurtosis=0.20009361829357264)\n",
      " \n",
      "1-rej\n",
      "DescribeResult(nobs=1000, minmax=(0.009240954024080539, 0.01841057706423599), mean=0.01323452164057285, variance=2.2726836696233563e-06, skewness=0.38844391582547955, kurtosis=0.14582178872297513)\n",
      " \n",
      "2\n",
      "DescribeResult(nobs=1000, minmax=(0.008641595921087708, 0.019699984973848172), mean=0.013887866134450961, variance=2.7052413477219267e-06, skewness=0.22370428171610285, kurtosis=0.16809009279741716)\n",
      " \n",
      "2-rej\n",
      "DescribeResult(nobs=1000, minmax=(0.00965044002982518, 0.021299277956816853), mean=0.014530889908432447, variance=2.7904865132953882e-06, skewness=0.26042871423100444, kurtosis=0.18732464299720997)\n",
      " \n",
      "1\n",
      "DescribeResult(nobs=1000, minmax=(509, 566), mean=540.94, variance=68.70110110110113, skewness=-0.020893967121893637, kurtosis=0.10840834392858278)\n",
      " \n",
      "1-rej\n",
      "DescribeResult(nobs=1000, minmax=(499, 541), mean=519.216, variance=42.35770170170169, skewness=0.0009648228017206664, kurtosis=0.22574466304073626)\n",
      " \n",
      "2\n",
      "DescribeResult(nobs=1000, minmax=(512, 572), mean=541.281, variance=69.97801701701701, skewness=0.0516029203903622, kurtosis=0.15310824519679356)\n",
      " \n",
      "2-rej\n",
      "DescribeResult(nobs=1000, minmax=(496, 544), mean=519.849, variance=41.601800800800795, skewness=0.06967276685750928, kurtosis=0.4226726356459882)\n",
      " \n",
      "1\n",
      "DescribeResult(nobs=1000, minmax=(25.697526047895966, 27.22543244806682), mean=26.532903962499837, variance=0.04353131815742382, skewness=-0.036857592328203764, kurtosis=0.13556700296824786)\n",
      " \n",
      "1-rej\n",
      "DescribeResult(nobs=1000, minmax=(25.457556083486075, 26.53823534149101), mean=26.008786207803787, variance=0.028718451606072073, skewness=-0.021444731686786057, kurtosis=0.237822078879788)\n",
      " \n",
      "2\n",
      "DescribeResult(nobs=1000, minmax=(25.809266829965, 27.319502907046736), mean=26.57064474835957, variance=0.04646303960490533, skewness=0.02072962039522246, kurtosis=0.1453507180383804)\n",
      " \n",
      "2-rej\n",
      "DescribeResult(nobs=1000, minmax=(25.406925679738208, 26.655094063859448), mean=26.054220728435315, variance=0.029449582451989333, skewness=-0.007208310100448025, kurtosis=0.4108498052724303)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "n = 1000000\n",
    "D = 2\n",
    "\n",
    "ell = 0.8 * np.sqrt(2)\n",
    "\n",
    "x_init = np.array([0, 0])\n",
    "x_goal = np.array([ell, 0])\n",
    "\n",
    "# r_n function\n",
    "def r(n, D):\n",
    "    return (n ** (-1/(2*D))) / 10\n",
    "    # designed for n = 10^6\n",
    "\n",
    "#############\n",
    "\n",
    "simulation_outputs = dict()     # key, value = process, dict\n",
    "\n",
    "for i in range(1, 3):\n",
    "    simulation_outputs[str(i)] = defaultdict(list)\n",
    "    simulation_outputs[str(i) + '-rej'] = defaultdict(list)\n",
    "    for j in range(1, 1001):\n",
    "        simulation_outputs[str(i)][j] = run_simulation(j * 10, process=i)\n",
    "        simulation_outputs[str(i) + '-rej'][j] = run_simulation_rej(j * 10, process=i)\n",
    "\n",
    "#############        \n",
    "\n",
    "lengths_free = defaultdict(list)\n",
    "counts_free = defaultdict(list)\n",
    "asymp_free = defaultdict(list)\n",
    "\n",
    "for k1 in simulation_outputs.keys():\n",
    "    for k2 in simulation_outputs[k1].keys():\n",
    "        lengths_free[k1].append(simulation_outputs[k1][k2]['length'])\n",
    "        counts_free[k1].append(simulation_outputs[k1][k2]['T'])\n",
    "        asymp_free[k1].append(simulation_outputs[k1][k2]['length'] * (simulation_outputs[k1][k2]['T'] ** 0.5))\n",
    "        \n",
    "const = ell - r(n, D)\n",
    "\n",
    "# statistics on length\n",
    "\n",
    "#print(describe(lengths_based - const))\n",
    "for k1 in simulation_outputs.keys():\n",
    "    print(str(k1))    \n",
    "    print(describe(lengths_free[k1] - const))\n",
    "    print(' ')\n",
    "    \n",
    "# statistics on T\n",
    "\n",
    "#print(describe(counts_based))\n",
    "for k1 in simulation_outputs.keys():\n",
    "    print(str(k1))    \n",
    "    print(describe(counts_free[k1]))\n",
    "    print(' ')\n",
    "    \n",
    "# statistics on asymp\n",
    "\n",
    "#print(describe(asymp_based))\n",
    "for k1 in simulation_outputs.keys():\n",
    "    print(str(k1))    \n",
    "    print(describe(asymp_free[k1]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "DescribeResult(nobs=1000, minmax=(5.280583179545495e-05, 0.01850947592742247), mean=0.006929341065037597, variance=2.0842106867664747e-05, skewness=0.4563956724487127, kurtosis=-0.7644932801474971)\n",
      " \n",
      "1-rej\n",
      "DescribeResult(nobs=1000, minmax=(4.79547687679549e-05, 0.01851137659059021), mean=0.007353426248397164, variance=2.1518632984879874e-05, skewness=0.33035121951098406, kurtosis=-0.81629061361491)\n",
      " \n",
      "2\n",
      "DescribeResult(nobs=1000, minmax=(3.7000341433834905e-05, 0.017976914993816262), mean=0.0069255549128103425, variance=2.037552335990687e-05, skewness=0.4500273480622023, kurtosis=-0.7151250508651565)\n",
      " \n",
      "2-rej\n",
      "DescribeResult(nobs=1000, minmax=(2.769114088763125e-05, 0.018313903539687093), mean=0.007382073074168936, variance=2.1349242597898637e-05, skewness=0.3409012024368316, kurtosis=-0.8047160509341715)\n",
      " \n",
      "1\n",
      "DescribeResult(nobs=1000, minmax=(79, 100), mean=89.309, variance=11.208727727727728, skewness=0.1273927686379826, kurtosis=-0.16853951671924694)\n",
      " \n",
      "1-rej\n",
      "DescribeResult(nobs=1000, minmax=(77, 96), mean=85.703, variance=6.8536446446446435, skewness=0.13014874660503611, kurtosis=-0.001665303024213749)\n",
      " \n",
      "2\n",
      "DescribeResult(nobs=1000, minmax=(80, 103), mean=89.218, variance=11.327803803803807, skewness=0.22398161056776075, kurtosis=0.26486866541705023)\n",
      " \n",
      "2-rej\n",
      "DescribeResult(nobs=1000, minmax=(78, 94), mean=85.681, variance=6.914153153153153, skewness=0.08327331739508671, kurtosis=-0.09582103022397392)\n",
      " \n",
      "1\n",
      "DescribeResult(nobs=1000, minmax=(9.891653513003673, 11.18833675833103), mean=10.577802767475845, variance=0.04162552772060751, skewness=0.05073306512382001, kurtosis=-0.09944240059656506)\n",
      " \n",
      "1-rej\n",
      "DescribeResult(nobs=1000, minmax=(9.765243153607093, 11.027401679422523), mean=10.366645160375656, variance=0.028508749648487156, skewness=0.06126361843818478, kurtosis=0.022752190507405956)\n",
      " \n",
      "2\n",
      "DescribeResult(nobs=1000, minmax=(9.972182657865186, 11.316767496713585), mean=10.572375927193514, variance=0.0424141619885545, skewness=0.16854059951235487, kurtosis=0.10359482532169251)\n",
      " \n",
      "2-rej\n",
      "DescribeResult(nobs=1000, minmax=(9.88098866895491, 10.922574774420227), mean=10.365579981925473, variance=0.029007873076840295, skewness=0.05366266982033465, kurtosis=-0.1396578738267502)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "n = 500000\n",
    "D = 2\n",
    "\n",
    "ell = 0.8 * np.sqrt(2)\n",
    "\n",
    "x_init = np.array([0, 0])\n",
    "x_goal = np.array([ell, 0])\n",
    "\n",
    "# r_n function\n",
    "def r(n, D):\n",
    "    return (n ** (-1/(2*D))) /2\n",
    "    # designed for n = 500000\n",
    "\n",
    "#############\n",
    "\n",
    "simulation_outputs = dict()     # key, value = process, dict\n",
    "\n",
    "for i in range(1, 3):\n",
    "    simulation_outputs[str(i)] = defaultdict(list)\n",
    "    simulation_outputs[str(i) + '-rej'] = defaultdict(list)\n",
    "    for j in range(1, 1001):\n",
    "        simulation_outputs[str(i)][j] = run_simulation(j * 10, process=i)\n",
    "        simulation_outputs[str(i) + '-rej'][j] = run_simulation_rej(j * 10, process=i)\n",
    "\n",
    "#############        \n",
    "\n",
    "lengths_free = defaultdict(list)\n",
    "counts_free = defaultdict(list)\n",
    "asymp_free = defaultdict(list)\n",
    "\n",
    "for k1 in simulation_outputs.keys():\n",
    "    for k2 in simulation_outputs[k1].keys():\n",
    "        lengths_free[k1].append(simulation_outputs[k1][k2]['length'])\n",
    "        counts_free[k1].append(simulation_outputs[k1][k2]['T'])\n",
    "        asymp_free[k1].append(simulation_outputs[k1][k2]['length'] * (simulation_outputs[k1][k2]['T'] ** 0.5))\n",
    "        \n",
    "const = ell - r(n, D)\n",
    "\n",
    "# statistics on length\n",
    "\n",
    "#print(describe(lengths_based - const))\n",
    "for k1 in simulation_outputs.keys():\n",
    "    print(str(k1))    \n",
    "    print(describe(lengths_free[k1] - const))\n",
    "    print(' ')\n",
    "    \n",
    "# statistics on T\n",
    "\n",
    "#print(describe(counts_based))\n",
    "for k1 in simulation_outputs.keys():\n",
    "    print(str(k1))    \n",
    "    print(describe(counts_free[k1]))\n",
    "    print(' ')\n",
    "    \n",
    "# statistics on asymp\n",
    "\n",
    "#print(describe(asymp_based))\n",
    "for k1 in simulation_outputs.keys():\n",
    "    print(str(k1))    \n",
    "    print(describe(asymp_free[k1]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
